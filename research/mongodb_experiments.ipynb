{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You are successfully connected to a MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "\n",
    "url = f\"mongodb+srv://tapankheni:tapankheni@cluster0.blfohxj.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "client = MongoClient(url)\n",
    "\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You are successfully connected to a MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = client[\"trail_mongodb_package\"]\n",
    "\n",
    "collection = database[\"collection_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"player_name\":\"Cristiano Ronaldo\",\n",
    "    \"no_goals\":\"750\",\n",
    "    \"national_team\":\"portugal\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertOneResult(ObjectId('6633c6902a71bb58239be467'), acknowledged=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.insert_one(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6633c6902a71bb58239be467'), 'player_name': 'Cristiano Ronaldo', 'no_goals': '750', 'national_team': 'portugal'}\n"
     ]
    }
   ],
   "source": [
    "records = collection.find()\n",
    "\n",
    "for record in records:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"player_name\":\"Lionel Messi\",\n",
    "        \"no_goals\":\"850\",\n",
    "        \"national_team\":\"Argentina\"\n",
    "    },\n",
    "    {\n",
    "        \"player_name\":\"Kylian Mbappe\",\n",
    "        \"no_goals\":\"250\",\n",
    "        \"national_team\":\"France\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('6633c7b92a71bb58239be468'), ObjectId('6633c7b92a71bb58239be469')], acknowledged=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from ensure import ensure_annotations\n",
    "from typing import Union\n",
    "\n",
    "class mongodb:\n",
    "    \n",
    "    def __init__(self, client_url: str, database_name: str, collection_name: str):\n",
    "        self.client_url = client_url\n",
    "        self.database_name = database_name\n",
    "        self.collection_name = collection_name\n",
    "\n",
    "    def __connect_to_db(self) -> MongoClient:\n",
    "        client = MongoClient(self.client_url)\n",
    "\n",
    "        try:\n",
    "            client.admin.command('ping')\n",
    "            print(\"Pinged your deployment. You are successfully connected to a MongoDB!\")\n",
    "            return client\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "        \n",
    "    @ensure_annotations\n",
    "    def __create_database(self, database_name: str):\n",
    "        client = self.__connect_to_db()\n",
    "        database = client[database_name]\n",
    "        print(\"Database created successfully!\")\n",
    "\n",
    "        return database\n",
    "    \n",
    "    @ensure_annotations\n",
    "    def __create_collection(self, collection_name: str, database_name: str):\n",
    "        if database_name == None:\n",
    "            database = self.__create_database(self.database_name)\n",
    "        else:\n",
    "            database = self.__create_database(database_name)\n",
    "\n",
    "        collection = database[collection_name]\n",
    "        print(\"Collection created successfully!\")\n",
    "\n",
    "        return collection\n",
    "    \n",
    "    @ensure_annotations\n",
    "    def insert(self, data: Union[dict, list], database_name: str = None,  collection_name: str = None):\n",
    "        if type(data) == list:\n",
    "            for record in data:\n",
    "                if type(record) != dict:    \n",
    "                    raise TypeError(\"Each individual record must be in dictionary format...\")\n",
    "                \n",
    "            if collection_name == None:\n",
    "                collection = self.__create_collection(self.collection_name, database_name)\n",
    "            else:\n",
    "                collection = self.__create_collection(collection_name, database_name)\n",
    "\n",
    "            collection.insert_many(data)\n",
    "\n",
    "        elif type(data) == dict:\n",
    "            if collection_name == None:\n",
    "                collection = self.__create_collection(self.collection_name, database_name)\n",
    "            else:\n",
    "                collection = self.__create_collection(collection_name, database_name)\n",
    "\n",
    "            collection.insert_one(data)\n",
    "\n",
    "        print(\"Data inserted successfully in the collection.\")\n",
    "\n",
    "    @ensure_annotations\n",
    "    def insert_dataframe(self, data_path: str, database_name: str = None, collection_name: str = None):\n",
    "        if data_path.endswith(\".csv\"):\n",
    "            df = pd.read_csv(data_path, encoding='utf-8')\n",
    "\n",
    "        elif data_path.endswith(\".xlsx\"):\n",
    "            df = pd.read_csv(data_path, encoding='utf-8')\n",
    "\n",
    "        json_records = list(json.loads(df.T.to_json()).values())\n",
    "\n",
    "        if collection_name == None:\n",
    "            collection = self.__create_collection(self.collection_name, database_name)\n",
    "        else:\n",
    "            collection = self.__create_collection(collection_name, database_name)\n",
    "\n",
    "        collection.insert_many(json_records)\n",
    "\n",
    "        print(\"Dataframe inserted successfully in the collection.\")\n",
    "\n",
    "    @ensure_annotations\n",
    "    def __get_size(self, path: Path) -> str:\n",
    "        \"\"\"get size in KB\n",
    "\n",
    "        Args:\n",
    "            path (Path): path of the file\n",
    "\n",
    "        Returns:\n",
    "            str: size in KB\n",
    "        \"\"\"\n",
    "        size_in_kb = round(os.path.getsize(path)/1024)\n",
    "        return f\"~ {size_in_kb} KB\"\n",
    "    \n",
    "    @ensure_annotations\n",
    "    def __create_directories(self, path_to_directories: list, verbose=True):\n",
    "        \"\"\"create list of directories\n",
    "\n",
    "        Args:\n",
    "            path_to_directories (list): list of path of directories\n",
    "            ignore_log (bool, optional): ignore if multiple dirs is to be created. Defaults to False.\n",
    "        \"\"\"\n",
    "        for path in path_to_directories:\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            if verbose:\n",
    "                print(f\"created directory at: {path}\")\n",
    "\n",
    "    @ensure_annotations\n",
    "    def __export_collection_as_dataframe(self, database_name: str, collection_name: str) -> pd.DataFrame:\n",
    "        client = self.__connect_to_db()\n",
    "\n",
    "        collection = client[database_name][collection_name]\n",
    "\n",
    "        df = pd.DataFrame(list(collection.find()))\n",
    "\n",
    "        if '_id' in df.columns.to_list():\n",
    "            df.drop(columns=['_id'], axis=1, inplace=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @ensure_annotations\n",
    "    def __export_data_into_file_path(self, database_name: str, collection_name: str, local_data_path: Path, root_dir: str) -> str:\n",
    "\n",
    "        data = self.__export_collection_as_dataframe(database_name, collection_name)\n",
    "\n",
    "        self.__create_directories([root_dir])\n",
    "\n",
    "        if not os.path.exists(local_data_path):\n",
    "            data.to_csv(local_data_path, index=False)\n",
    "            return f\"exported data from mongoDB stored at {local_data_path}\"\n",
    "        \n",
    "        else:\n",
    "            return f\"file already exists of size: {self.__get_size(local_data_path)}\"\n",
    "\n",
    "    @ensure_annotations\n",
    "    def get_data(self, database_name: str, collection_name: str, local_data_path: Path, root_dir: str) -> str:\n",
    "        return self.__export_data_into_file_path(database_name, collection_name, local_data_path, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_url = f\"mongodb+srv://tapankheni:tapankheni@cluster0.blfohxj.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "database_name = \"trail_mongodb_package\"\n",
    "collection_name = \"collection_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You are successfully connected to a MongoDB!\n",
      "Database created successfully!\n",
      "Collection created successfully!\n",
      "Dataframe inserted successfully in the collection.\n"
     ]
    }
   ],
   "source": [
    "mongo = mongodb(client_url=client_url, database_name=database_name, collection_name=collection_name)\n",
    "\n",
    "data_path = \"/Users/tapankheni/Data_Science/Data Science Projects/MongoDB_Connector_PKG/research/wafers.csv\"\n",
    "mongo.insert_dataframe(data_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You are successfully connected to a MongoDB!\n",
      "created directory at: ../artifacts/data_ingestion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file already exists of size: ~ 363 KB'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo = mongodb(client_url=client_url, database_name=database_name, collection_name=collection_name)\n",
    "\n",
    "mongo.get_data(database_name=database_name, collection_name=collection_name, local_data_path=Path(\"../artifacts/data_ingestion/wafers.csv\"),\n",
    "               root_dir=\"../artifacts/data_ingestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: custom-db-connector in /Users/tapankheni/Data_Science/Data Science Projects/MongoDB_Connector_PKG/src (0.0.2)\n",
      "Requirement already satisfied: ensure==1.0.2 in /Users/tapankheni/anaconda3/envs/mongodbPKG/lib/python3.8/site-packages (from custom-db-connector) (1.0.2)\n",
      "Requirement already satisfied: py-youtube==1.1.7 in /Users/tapankheni/anaconda3/envs/mongodbPKG/lib/python3.8/site-packages (from custom-db-connector) (1.1.7)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/tapankheni/anaconda3/envs/mongodbPKG/lib/python3.8/site-packages (from ensure==1.0.2->custom-db-connector) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## examine the package\n",
    "%pip install custom-db-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1457415950.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import custom-db-connector\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import custom-db-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mongodbPKG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
